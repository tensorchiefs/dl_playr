---
title: "Boston"
author: "Beate and Oliver"
date: "1/16/2020"
output: pdf_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=6, fig.height=4)
```

## Goal of this script

We want to implement linear transformation models in NN and compare the achieved NLL and estimated ceofficients with the MLT results.

We fit a transformation function $h: (y|x) \rightarrow (z|x)$ with the property $(z|x)=h(y|x) \sim N(0,1)$

In a  **linear** transformation model the transformation function has the special form:
$h_{Y}(y)-\sum_i \beta_i x_i$

Then we know, that.

* $F_{Y{|X=x}}(y)=F_z(h_{Y}(y)-\sum_i \beta_i x_i)$


## Importing the required packages
```{r}
library(MASS)
library(ggplot2)
library(mlt)
library(basefun)
library(keras)
library(tensorflow)
library(tfprobability)
T_STEPS = 35000
nb = 8  # order defining the Number of Bernstein fct in polynom
```

Source functions h and h_dash in w and w/o batch magic

```{r pressure, echo=TRUE, error=TRUE}
# source("mlt_utils.R")  # eg scaling fct
# # preparing eval_h an eval_h_dash, fct implemented in tfp
# source("mlt_utils_keras_v2.R")  # causes error when knittering
#source('https://raw.githubusercontent.com/tensorchiefs/dl_playr/master/mlt/bern_utils.R')
#source('~/Documents/workspace/dl_playr/mlt/bern_utils.R')
source('bern_utils.R')

source('data.R')
```


## Loading the data
We scale the y-varible to [0,1]
```{r}
xy_dat = get_data_boston()
dat = xy_dat$dat
sum(dat$y**2) # 299626.3 to compare with BH data in paper
dat$y_obs = dat$y
dat$y = NULL
y_range = xy_dat$scale
dat$y_scale = dat$y_obs
dat$y_obs = NULL
x = xy_dat$x
y = xy_dat$y
```


## Defining the model
We set up the formula for the model:
```{r}
fm_large = (y_scale ~ crim + zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + b + lstat)
#fm_small = (y_scale ~  rm + lstat) #lm log lik 346
#fm_uni = (y_scale ~  rm)
(fm = fm_large)
is_univariate = TRUE
sum(dat$rm**2)  # 20234.6 to compare with BH data in paper
```

## Baseline Linear Model
```{r}
fit_lm = lm(fm, data=dat)
fit_lm$coef
(logLik_lm=logLik(fit_lm) )/nrow(dat) + log(y_range)# the larger the better
```


## MLT fit and results

### Variable and Model definition and fit
```{r}
len_theta = nb+1
# specify a numeric variable with data in [0,1] and principle bounds [0,Inf] 
var_y <- numeric_var("y_scale", support = c(0, 1), bounds = c(-Inf, Inf), add = c(0,0))
# what is done with the bound information (default bounds c(-INF, INF)

# set up monoton increasing polynomial of order nb with Bernstein basis function
bb <- Bernstein_basis(var_y, order=nb, ui="increasing")

# set up grid in interval supp+add -> gives data.frame with col y_scale
y_grid <- as.data.frame(mkgrid(bb, n = 500))

# set up model for mlt
ctm = ctm(bb, shift=fm[-2L], data=dat, todistr="Normal") 
#~-1 + crim
#ctm = ctm(bb, shift = ~ b + crim - 1, data=dat, todistr="Normal") 
# fm[-2L] defnes the basis function for the shift term h_y(y) in h(y|x)=h_y(y)+h_x(x) 
# the intercept is included in the baseline-trafo h_y(y) (not in linear predictor h_x(x))
```

Fit of the model:

```{r}
# fit the mlt model
mlt_fit <- mlt(ctm, data = dat, verbose=TRUE)
```

## logLik with MLT
```{r}
(logLik_mlt = logLik(mlt_fit))  #  df = nr-theta + nr-beta
# compare to logLik of the baseline model - the larger the better
NLL_MLT = -logLik_mlt / nrow(dat) + log(y_range)
```

## Estimated coefficients with MLT

Get the coefficients of the trafo h from the mlt fit:
```{r}
( mlt_fit$coef )

( theta = mlt_fit$coef[1:(nb+1)] )
( beta = mlt_fit$coef[(nb+2):length(mlt_fit$coef)] )
```


The conditional PDF for some observations
```{r}
  f_mlt = predict(mlt_fit, newdata=dat,  q=y_grid$y_scale, type='density')
  
  q_mlt = predict(mlt_fit, newdata=dat, 
                  prob=c(0.025,0.25,0.5, 0.75,0.975), type='quantile')
  q_mlt = t(q_mlt)
  #q_mlt = matrix(q_mlt$exact, ncol = 5, byrow = TRUE)
  set.seed(3)
  idx = sample(1:ncol(f_mlt))[1:10]
  m = max(f_mlt[,idx])
  plot(y_grid$y_scale, f_mlt[,idx[1]], type='l',col='red', ylim=c(0,4),
       main="mlt-predicted CPD for some picked predictors")
  for (i in idx){
    lines(y_grid$y_scale, f_mlt[,i], col=i)  
  }
```

\newpage
# NN
## NN approach for a linear shift model, modeled with NN


Fitting means to find the $nb$ coefficients *theta* for the Bernsteinpolynom which approximaties the transformation function with $nb$ being set to:
```{r}
nb
```

## Preparing input and output
```{r}
y = tf$Variable(as.matrix(dat$y_scale)[,drop=FALSE], dtype='float32')
y$shape # has to be (#y,1)

# conditional - we give the rm-variables as input to the NN
#x = tf$Variable(as.matrix(dat$rm)[,drop=FALSE], dtype='float32')

#x = tf$Variable(as.matrix(dat[,c('rm','lstat'),drop=FALSE]), dtype='float32')

#dat$chas = as.numeric(as.character(dat$chas))
x = tf$Variable(x, dtype='float32') #all
x$shape  # has to be (#y,1) for a univariate model

source('model_3.R')
source('bern_utils.R')
source("model_utils.R")
x_dim = as.integer(dim(x)[2])
model_3 = new_model_3(len_theta = as.integer(len_theta), x_dim = x_dim, y_range=y_range)
T_OUT = 100
run = 1
history = model_train(model_3, make_hist(), x_train = x, y_train = y, x_test = x, y_test = y, T_STEPS=T_STEPS)
```

```{r}
history$step = as.integer(history$step)
history$fold = as.integer(history$fold)
history$nll_train = as.numeric(history$nll_train)
history$nll_test = as.numeric(history$nll_test)
history$OK = NULL# = as.numeric(history$OK)

library(tidyr)
h = gather(history, 'sample', 'loss', nll_train:nll_test)
h$loss = as.numeric(h$loss)
h$sample = as.factor(h$sample)
h$fold = as.factor(h$fold)
hh =h[!is.na(h$loss),] 

ggplot(hh, aes(x=step,y=loss, color=sample, linetype=fold)) +
ylim(2,5) + geom_hline(yintercept=NLL_MLT)+  geom_line() + facet_grid(. ~ method)
```

# Compare NN model to MLT model

## Get beta coefficients

```{r}
( beta_nn = as.numeric( model_3$model_beta$get_weights()[[1]]) )
 ( beta_mlt = mlt_fit$coef[(len_theta+1):(len_theta+ncol(x))] )
  beta_nn/beta_mlt
```

## Get theta coefficients
```{r}
  one = tf$ones(shape = c(1,1))
  ( theta_nn = to_theta(model_3$model_hy(one)) )
  ( theta_mlt = mlt_fit$coef[1:len_theta] )

  theta_nn$numpy()/theta_mlt
```

## predict baseline trafo (first part of trafo w/o shift)

```{r}

#nn
out_row = model_3$model_hy(one) #Pick row and compute CPD
df_nn = bernp.p_y_h(model_3$bernp, out_row, from = 0, to = 1, length.out = length(y_grid$y_scale))
h_y_nn = df_nn$h

# mlt
h_y_mlt = predict(bb, newdata = y_grid, coef = theta_mlt, type='trafo')

plot(df_nn$y, h_y_nn,  type='l', lty=2)
lines(y_grid$y_scale, h_y_mlt, type='l',col='green')

```


## Predict full trafo (all parts of trafo inclusive shift) for picked observation
```{r}
# nn
pick_idx = 1
shift = beta_nn %*% x[pick_idx,1:length(beta_nn)]$numpy()
out_row = model_3$model_hy(one) #Pick row and compute CPD
df_nn = bernp.p_y_h(model_3$bernp, out_row, from = 0, to = 1, length.out = 100, out_eta = shift)
h_full_nn = df_nn$h

# mlt:
h_full_mlt = predict(mlt_fit, newdata = dat[pick_idx,], q=y_grid$y_scale, type='trafo')

plot(df_nn$y, h_full_nn, type='l', col='green')
lines(y_grid$y_scale, h_full_mlt)

```

## Predict CPD for picked observations
```{r}
# NN

cpd_nn = df_nn$p_y

# mlt:
cpd_mlt = predict(mlt_fit, newdata = dat[pick_idx,], q=y_grid$y_scale, type='density')


plot(df_nn$y, cpd_nn, ylim=c(0,8), type="l", col='green')
lines(y_grid$y_scale, cpd_mlt, lty=2)

```












